{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9b87016e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importメソッド\n",
    "import spacy   #spacyライブラリ（自然言語処理のため）\n",
    "import ginza   #ginzaライブラリ（spacyを日本語対応させる）\n",
    "from spacy import displacy   #displacyライブラリ（文章構造の視覚化）\n",
    "import csv     #csvライブラリ（TSVファイルの入出力に必要）\n",
    "\n",
    "#定数宣言\n",
    "SUBJECT = \"Who\"#主語のproperty分類を表した定数\n",
    "OBJ = \"Obj\"#目的語のproperty分類を表した定数\n",
    "#FILE_NAME = 'プログラム試験用'\n",
    "#FILE_NAME = 'DevilsFoot'\n",
    "#FILE_NAME = 'SilverBlaze'\n",
    "#FILE_NAME = 'ResidentPatient'\n",
    "#FILE_NAME = 'DancingMen置換'#元データからプログラム処理の邪魔になる\"を置換したデータ\n",
    "#FILE_NAME = 'ACaseOfIdentity'\n",
    "FILE_NAME = 'AbbeyGrange'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "13106455",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "出力ファイルの初期化\n",
      "出力完了\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load('ja_ginza_electra')\n",
    "\n",
    "\n",
    "class SentSVO:                #文章を主語・述語・目的語に分解するクラス\n",
    "    def __init__(self,sent,sent_id):\n",
    "        self.subject = [\"\"]        #主語となる文字列を保存するlist型変数(主語が複数ある場合は要素ごとに分ける\n",
    "        self.obj = []              #目的語となる文字列を保存するlist型変数(主語が複数ある場合は要素ごとに分ける\n",
    "        self.obj_list_num = 0         #目的語の要素数（目的語はsent.rootの子トークンに複数あるためインタスタンス変数として管理）\n",
    "        self.hasPredicate = \"\"   #述語となる文字列を保存するlist型変数(主語が複数ある場合は要素ごとに分ける\n",
    "        self.first_num = 0          #係り受け関係（自身含む）にある最初の単語番号を探すための変数(初期値は変数として宣言するためのもの)\n",
    "        self.last_num = 0           #係り受け関係（自身含む）にある最後の単語番号を探すための変数(初期値は変数として宣言するためのもの)\n",
    "        self.sent = sent            #解析する文\n",
    "        self.sent_id = sent_id      #文章ID\n",
    "        self.cheak = True       #SVO分解したものの正誤判定のための変数\n",
    "        self.scene_cheak = [\"〇\",\"〇\",\"〇\"]  #場面ごとのSVOの正誤判定(リストの0:主語、1:述語、2:目的語)\n",
    "        self.dislocated_flag = False  #転置「dislocated」の有無を判定する変数\n",
    "        self.property_stock = \"\"  #目的語・述語のプロパティ保存用（インスタンス変数にしてあるのはプロパティの分類が出来るようになったときに正誤判定部分を関数分けするため）\n",
    "    \n",
    "    def first_search(self,children):          #係り受け（自身含む）の最初を探して、単語番号を保存するクラス関数\n",
    "        if not children:                      #子トークンがない場合は関数終了\n",
    "            return\n",
    "        elif self.first_num > children[0].i:         \n",
    "            self.first_num = children[0].i\n",
    "            self.first_search(list(children[0].children))\n",
    "    \n",
    "    def last_search(self,children):       #係り受け（自身含む）の最後を探して、単語番号を保存するクラス関数\n",
    "        if not children:                  #子トークンがない場合は関数終了\n",
    "            return\n",
    "        elif self.last_num < children[-1].i:\n",
    "            self.last_num = children[-1].i\n",
    "            self.last_search(list(children[-1].children))\n",
    "\n",
    "    def subject_search(self,token):    #この単語に係り受けしている単語の中から主語として必要なものを付け足すクラス関数\n",
    "        self.first_num = token.i               #自身の単語番号で初期化（最初の単語番号）\n",
    "        self.last_num = token.i                #自身の単語番号で初期化（最後の単語番号）\n",
    "        children = list(token.children)    #単語tokenを係り受けしている単語（複数）を取得し、list型でchildrenに代入\n",
    "        self.first_search(children)          #主語の最初の単語番号を探す\n",
    "        self.last_search(children)           #主語の最後の単語番号を探す\n",
    "        list_num = 0                           #リストsubjectの要素数を管理するための変数\n",
    "\n",
    "\n",
    "        if self.sent[self.last_num].dep_ == \"punct\":  #句読点だった場合は一つ前の単語で判定\n",
    "            self.last_num -= 1\n",
    "            \n",
    "        if not self.sent[self.last_num].dep_ == \"case\":       #係り受け関係の最後の単語が助詞でない場合はその単語も含む\n",
    "            self.last_num += 1\n",
    "        \n",
    "        for num in range(self.first_num,self.last_num):     #係り受け関係の最初の単語から最後の単語まで順番に付け足していく\n",
    "            if self.sent[num].dep_==\"case\" and (self.sent[num].text==\"と\" or self.sent[num].text==\"や\"):\n",
    "                #特定の助詞の場合は付け足さずに要素数を増やし以後そちらに単語を付け足す\n",
    "                list_num += 1\n",
    "                self.subject.append(\"\")\n",
    "                continue\n",
    "            self.subject[list_num] += self.sent[num].text   #単語を結合していく\n",
    "        \n",
    "    def obj_search(self,token):              #この単語に係り受けしている単語の中から目的語として必要なものを付け足すクラス関数\n",
    "        self.first_num=token.i               #自身の単語番号で初期化（最初の単語番号）\n",
    "        self.last_num=token.i                #自身の単語番号で初期化（最後の単語番号）\n",
    "        children=list(token.children)      #単語tokenを係り受けしている単語（複数）を取得し、list型でchildrenに代入\n",
    "        self.first_search(children)          #目的語の最初の単語番号を探す\n",
    "        self.last_search(children)           #目的語の最後の単語番号を探す\n",
    "        \n",
    "        #↓係り受け関係の最後の単語が助詞でない場合はその単語も含む\n",
    "        if not self.sent[self.last_num].dep_ == \"case\":  \n",
    "            self.last_num += 1\n",
    " \n",
    "        for num in range(self.first_num,self.last_num):     #係り受け関係の最初の単語から最後の単語まで順番に付け足していく\n",
    "            if self.sent[num].dep_==\"case\" and (self.sent[num].text==\"と\" or self.sent[num].text==\"や\" \\\n",
    "            or self.sent[num].text==\"から\"):#特定の助詞の場合は付け足さずに要素数を増やして以後そちらに単語を付け足す\n",
    "                self.obj_list_num += 1\n",
    "                self.obj.append(\"\")\n",
    "                continue\n",
    "            self.obj[self.obj_list_num] += self.sent[num].text  #単語を結合していく\n",
    "            #print(\"残ってる\",self.obj)\n",
    "            \n",
    "    def hasPredicate_search(self,token):       #述語の取得\n",
    "        self.first_num = token.i               #自身の単語番号で初期化（最初の単語番号）\n",
    "        self.last_num = token.i                #自身の単語番号で初期化（最後の単語番号）\n",
    "        rootchildren=list(token.children)  #単語tokenを係り受けしている単語（複数）を取得し、list型でchildrenに代入\n",
    "        \n",
    "        #述語はrootスタートなので一度目の単語番号索敵は条件付けが必要\n",
    "        for rootchild in rootchildren:   #主語系、目的語系以外の係り受け先で最も単語番号の小さい単語を探索\n",
    "            if self.first_num > rootchild.i:\n",
    "                if self.dislocated_flag:  #転置がある場合は\"obl\"\"obj\"\"dislocated\"以外から\n",
    "                    if \"obl\"!=rootchild.dep_ and \"obj\"!=rootchild.dep_ and \"dislocated\"!=rootchild.dep_:\n",
    "                        self.first_num = rootchild.i\n",
    "                        self.first_search(list(rootchild.children))    #述語の最初の単語番号を探す\n",
    "                else:  #転置がない場合は\"obl\"\"obj\"\"nsubj\"\"csubj\"以外から\n",
    "                    if \"nsubj\"!=rootchild.dep_ and \"csubj\"!=rootchild.dep \\\n",
    "                    and \"obl\"!=rootchild.dep_ and \"obj\"!=rootchild.dep_ :\n",
    "                        self.first_num = rootchild.i\n",
    "                        self.first_search(list(rootchild.children))    #述語の最初の単語番号を探す                        \n",
    "            else:\n",
    "                break\n",
    "                \n",
    "        for rootchild in reversed(rootchildren):#主語系、目的語系以外の係り受け先で最も単語番号の大きい単語を探索\n",
    "            if self.last_num < rootchild.i:\n",
    "                if self.dislocated_flag:  #転置がある場合は\"obl\"\"obj\"\"dislocated\"以外から\n",
    "                    if \"obl\"!=rootchild.dep_ and \"obj\"!=rootchild.dep_ and \"dislocated\"!=rootchild.dep_:\n",
    "                        self.last_num = rootchild.i\n",
    "                        self.last_search(list(rootchild.children))    #述語の最後の単語番号を探す                          \n",
    "                else:  #転置がない場合は\"obl\"\"obj\"\"nsubj\"\"csubj\"以外から\n",
    "                    if \"nsubj\"!=rootchild.dep_ and \"csubj\"!=rootchild.dep \\\n",
    "                    and \"obl\"!=rootchild.dep_ and \"obj\"!=rootchild.dep_ :\n",
    "                        self.last_num = rootchild.i\n",
    "                        self.last_search(list(rootchild.children))    #述語の最後の単語番号を探す\n",
    "            else:\n",
    "                break\n",
    "          \n",
    "        #係り受け関係の最後の単語が助詞でない場合はその単語も含む\n",
    "        if not self.sent[self.last_num].dep_ == \"case\":  \n",
    "            self.last_num += 1\n",
    "        \n",
    "        #係り受け関係の最初の単語から最後の単語まで順番に付け足していく\n",
    "        for num in range(self.first_num,self.last_num):\n",
    "            self.hasPredicate += self.sent[num].text  #単語を結合していく\n",
    "            #print(\"残ってる\",self.obj)\n",
    "        \n",
    "    def svo_parse(self):   #主語・述語・目的語の分解を行うクラス関数（外部から呼び出す）        \n",
    "        if not self.sent:   #文字列が存在しない場合はreturn\n",
    "            return\n",
    "        \n",
    "        for token in self.sent:\n",
    "            if token.dep_ == \"dislocated\":   #解析した文から転置「dislocated」を探す\n",
    "                self.dislocated_flag = True\n",
    "                self.subject_search(token) #転置先を主語として扱う\n",
    "            \n",
    "        rootchildren = list(self.sent.root.children)   #単語root（述語）に直接係り受けしている単語をlist型で取得\n",
    "        for rootchild in rootchildren:                              #取得した単語（複数）をすべて参照\n",
    "            if \"nsubj\"==rootchild.dep_ or \"csubj\"==rootchild.dep_:  #主語や主部の単語があれば\n",
    "                if not self.dislocated_flag:                        #転置が無ければ\n",
    "                    self.subject_search(rootchild)                #主語（主部）の係り受け関係を取得\n",
    "            elif \"obl\"==rootchild.dep_ or \"obj\"==rootchild.dep_:    #目的語の単語があれば\n",
    "                self.obj.append(\"\")                                   #目的語を保存するlistの要素を追加する\n",
    "                self.obj_search(rootchild)                            #目的語の係り受け関係をすべて取得\n",
    "                self.obj_list_num += 1                                  #次に参照する目的語のlistの要素を変更\n",
    "        self.hasPredicate_search(self.sent.root)                  #述語の係り受け先を取得\n",
    "        \n",
    "    \n",
    "    def svo_cheak(self,token_mode,cheak_list,token,scene_cheak_num):        #取得結果と手本（人の手で作ったもの）の比較のためのクラス関数\n",
    "            self.cheak = False   #正誤判定の変数\n",
    "            #print(cheak_list)#テスト用\n",
    "            for cheak in cheak_list:  #この場面IDにおける答えの単語群を一行ずつループ参照\n",
    "                #print(cheak[1],token_mode,\"1つめ\")#テスト用\n",
    "                if cheak[1] == token_mode:\n",
    "                    #print(cheak[2],token,\"2つめ\")#テスト用\n",
    "                    if cheak[2] == token:    #SVO分解して取得した結果と手本の答えを比較\n",
    "                        self.cheak = True       #cheak_listにあったことを記録\n",
    "                        break\n",
    "    \n",
    "    def svo_print(self,cheak_list,true_properties_num,token_properties):           #主語・述語・目的語を出力する関数\n",
    "        with open(\"../experiment/\"+FILE_NAME+\"SVO結果.tsv\",mode=\"a+\",encoding='utf-8',newline='') as output_file:   #出力ファイルを作成し、一行ずつ出力して追加する\n",
    "            writer = csv.writer(output_file,delimiter=\"\\t\")   #出力形式をTSVファイルに設定\n",
    "            #print(self,cheak_list)#正解データの確認テスト用\n",
    "            \n",
    "            #対象文\n",
    "            line_stock = [[self.sent_id,\"対象文\",self.sent,\"\",\"\"]]  #対象文行をリストに保存\n",
    "            #print(cheak_list)#テスト用\n",
    "            \n",
    "            #主語\n",
    "            part_cheak = \"×\"   #場面ごとの判定において×か△を評価するための変数\n",
    "            for subject in self.subject:                             \n",
    "                self.svo_cheak(SUBJECT,cheak_list,subject,0)                       #主語を正誤判定\n",
    "                if self.cheak:#正解であればpart_cheakを△にする\n",
    "                    part_cheak = \"△\"\n",
    "                else:#不正解であればself.scene_cheak[0]を×にする\n",
    "                    self.scene_cheak[0] = \"×\"\n",
    "                line_stock.append([self.sent_id,SUBJECT,subject,self.cheak,\"\"])   #主語行をリストに保存\n",
    "           \n",
    "            if self.scene_cheak[0] == \"×\":#主語の中に不正解があるなら、part_cheak（全て不正解か部分不正解か）を反映\n",
    "                self.scene_cheak[0] == part_cheak\n",
    "            if len(self.subject) == 0:#主語が一つもない場合は\"無\"\n",
    "                self.scene_cheak[0] = \"無\"\n",
    "                \n",
    "            #述語\n",
    "            #self.svo_cheak(\"hasPredicate\",cheak_list,self.hasPredicate)#述語を正誤判定（インスタンス内変数self.hasPredicateを引数にしているのは単語ごとに関数を使い分けるため）\n",
    "            #####現状は述語の種類分け（hasPredicateかhasProperty）まで出来てないので述語の正誤判定は以下でする###############\n",
    "            self.cheak = False   #正誤判定の変数（0なら正、1なら誤）\n",
    "            for cheak in cheak_list:  #この場面IDにおける答えを一行ずつループ参照\n",
    "                if cheak[1]==\"hasProperty\" or cheak[1]==\"hasPredicate\":\n",
    "                    if cheak[2] == self.hasPredicate:    #SVO分解して取得した結果と手本の答えを比較\n",
    "                        self.cheak = True       #cheak_listにあったことを記録\n",
    "                        self.property_stock = cheak[1]   #述語のプロパティの種類を保存する\n",
    "            ################################################################################################################                      \n",
    "            if self.cheak:\n",
    "                #self.property_stockと一致する述語のプロパティ数を加算（正解数）\n",
    "                if self.property_stock==token_properties[16]:#正解のプロパティが\"hasProperty\"であれば\n",
    "                    true_properties_num[16] += 1   #正解数を加算\n",
    "                if self.property_stock==token_properties[17]:#正解のプロパティが\"hasPredicate\"であれば\n",
    "                    true_properties_num[17] += 1   #正解数を加算\n",
    "            else:#不正解であればself.scene_cheak[1]を×にする\n",
    "                    self.scene_cheak[1] = \"×\"            \n",
    "            line_stock.append([self.sent_id,\"hasPredicate\",self.hasPredicate,self.cheak,self.property_stock])    #述語行をリストに保存\n",
    "            \n",
    "            #目的語\n",
    "            part_cheak = \"×\"   #場面ごとの判定において×か△を評価するための変数\n",
    "            for obj in self.obj:            \n",
    "                #####現状は目的語の種類分けまで出来てないので目的語の正誤判定は以下でする###############\n",
    "                self.cheak = False   #正誤判定の変数（0なら正、1なら誤）\n",
    "                self.property_stock = \"判別不能\" #答えにおける目的語のプロパティ\n",
    "                for cheak in cheak_list:  #この場面IDにおける答えを一行ずつループ参照\n",
    "                    if cheak[1]!=SUBJECT and cheak[1]!=\"hasPredicate\" and cheak[1]!=\"hasProperty\":\n",
    "                        if cheak[2] == obj:    #SVO分解して取得した結果と手本の答えを比較\n",
    "                            self.cheak = True       #cheak_listにあったことを記録\n",
    "                            self.property_stock = cheak[1]   #目的語のプロパティの種類を保存する\n",
    "                            break#SVO結果と一致する答えがあれば、ループを終了する。\n",
    "                ########################################################################################  \n",
    "                if self.cheak:  #self.cheakが真の場合（self.cheakにTrueを代入する時に行わないのはプロパティの判別が出来れば関数svo_cheakで行うから）\n",
    "                    part_cheak = \"△\"   #正解であればpart_cheakを△にする\n",
    "                    #↓self.property_stockと一致する目的語のプロパティ数を加算（正解数）\n",
    "                    for num in range(16):            #目的語のプロパティ数分ループ\n",
    "                        if self.property_stock==token_properties[num]:#正解のプロパティと目的語の各プロパティを比較\n",
    "                            true_properties_num[num] += 1\n",
    "                else:#不正解であればself.scene_cheak[2]を空にする\n",
    "                    self.scene_cheak[2] = \"×\"\n",
    "                line_stock.append([self.sent_id,OBJ,obj,self.cheak,self.property_stock]) #SVO結果の目的語を行としてリストに保存               \n",
    "            \n",
    "            if self.scene_cheak[2] == \"×\":#主語の中に不正解があるなら、part_cheak（×か△）を反映\n",
    "                self.scene_cheak[2] = part_cheak\n",
    "            if self.obj_list_num == 0:#目的語が一つもない場合は\"無\"\n",
    "                self.scene_cheak[2] = \"無\"\n",
    "            #print(part_cheak,self.scene_cheak[2],self.sent_id) #テスト用\n",
    "            \n",
    "            for line in line_stock:#場面の各行を纏めて出力\n",
    "                writer.writerow(line+self.scene_cheak)\n",
    "        \n",
    "        return true_properties_num\n",
    "\n",
    "#tsvファイルの読み込み\n",
    "sent_id = \"0\"  #場面ID（文ごとのIDでもある）\n",
    "\n",
    "all_properties_num = [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]#目的語の各プロパティの総数(詳しくは「現状とプロパティ」より)\n",
    "true_properties_num = [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]#目的語の各プロパティの正解数(詳しくは「現状とプロパティ」より)\n",
    "token_properties = [\"Why\",\"What\",\"How\",\"When\",\\\n",
    "                  \"Where\",\"Whom\",\"From\",\"To\",\\\n",
    "                  \"On\",\"Under\",\"Left\",\"Right\",\\\n",
    "                  \"Near\",\"NextTo\",\"MiddleOf\",\"Opposite\",\\\n",
    "                  \"hasProperty\",\"hasPredicate\"]\n",
    "\"\"\"\n",
    "↑目的語と述語の各プロパティの種類\n",
    "(変数「all_properties_num」と変数「true_properties_num」の要素順と対応している)\n",
    "\"\"\"\n",
    "\n",
    "with open(\"../experiment/\"+FILE_NAME+\"SVO結果.tsv\",mode=\"w\",encoding='utf-8',newline='') as file:\n",
    "    print(\"出力ファイルの初期化\") #出力ファイルの初期化       \n",
    "    writer = csv.writer(file,delimiter=\"\\t\")   #出力形式をTSVファイルに設定\n",
    "    writer.writerow([\"ID\",\"Property\",\"原文\",\"正誤判定\",\"正解Propertyの詳細\",\"場面内の主語\",\"場面内の述語\",\"場面内の目的語\"])#見出し行（エクセルにしたとき）\n",
    "with open(\"../experiment/\"+FILE_NAME+\".tsv\",mode=\"r\", encoding='utf-8', newline='') as input_file:      #入力ファイルを読み込む\n",
    "    read_list = list(csv.reader(input_file, delimiter='\\t'))    #読み込んだ入力ファイルをtsv形式に整形してリスト型として代入\n",
    "    for cols in read_list:\n",
    "        #print(cols)   #上手くいっていない行確認テスト用\n",
    "        if \"対象文\" == cols[1]:                        #2列目propertyが「対象文」である行を取得\n",
    "            sent_id = cols[0]                          #場面IDを更新\n",
    "            doc = nlp(cols[2])                         #取得した行の3列目原文を取得\n",
    "            #print(list(doc.sents))#if len(list(doc.sents))==1:のテスト用\n",
    "            if len(list(doc.sents))==1:\n",
    "                for sent in doc.sents: #文章を一文ずつ分けてループ処理する(将来短文ではなく長文に対処するため)\n",
    "                    #print(sent)  #上手くいっていない対象文確認テスト用\n",
    "                    svo = SentSVO(sent,sent_id)          #インスタンスの作成\n",
    "                    svo.svo_parse()                      #SVO分解を行う\n",
    "\n",
    "                    #グラフ表示（試験用）\n",
    "                    #displacy.render(doc, style='dep', jupyter=True, options={'compact':True, 'distance': 90})\n",
    "\n",
    "                    index_num = read_list.index(cols)   #read_listの現在参照している要素数\n",
    "                    cheak_list = []   #現在の場面IDにおける入力ファイルの正解を保存するためのリスト型変数\n",
    "\n",
    "                    #read_listの（colsの要素数＋１）から（最後の要素数）までループ<same_num_colsにはcolsと同じ場面IDである１行が格納される>\n",
    "                    for same_num_cols in read_list[index_num+1:read_list.index(read_list[-1])+1]:\n",
    "                        if sent_id!=same_num_cols[0]:    #\"対象文\"と現在の行が場面IDが異なる場合はループを終了\n",
    "                            break\n",
    "                        else:\n",
    "                            if not same_num_cols[2]:#行の要素2（主語とか述語とかが入っている）が空ならスキップ\n",
    "                                continue\n",
    "                            else:\n",
    "                                #print(read_list[index_num+addition_num][2])#テスト用\n",
    "                                cheak_list.append(same_num_cols)\n",
    "                                #答えのリストから目的語の種類と一致する場合は加算\n",
    "                                for num in range(18):\n",
    "                                    if same_num_cols[1]==token_properties[num]:#same_num_colsを述語・目的語のプロパティと同じものがないか比較（主語はプロパティが一つしかないので判定しない）\n",
    "                                        all_properties_num[num] += 1#同じものがあれば、そのプロパティの総数を加算\n",
    "                    #SVO分解結果を出力し、目的語プロパティの種類ごとに正解数を加算してtrue_properties_numに保存。\n",
    "                    true_properties_num = svo.svo_print(cheak_list,true_properties_num,token_properties)\n",
    "            else:\n",
    "                #print(\"2文以上あるので回避します\",list(doc.sents))\n",
    "                with open(\"../experiment/\"+FILE_NAME+\"SVO結果.tsv\",mode=\"a+\",encoding='utf-8',newline='') as output_file:   #出力ファイルを作成し、一行ずつ出力して追加する\n",
    "                    writer = csv.writer(output_file,delimiter=\"\\t\")   #出力形式をTSVファイルに設定                \n",
    "                    writer.writerow([sent_id,\"対象文\",cols[2],\"\",\"\",\"\",\"\",\"\",\"解析不可\"])\n",
    "\n",
    "#記録した目的語プロパティの種類ごとの正解数と総数をファイルに出力\n",
    "with open(\"../experiment/\"+FILE_NAME+\"プロパティ.tsv\",mode=\"w\",encoding='utf-8',newline='') as obj_file:  \n",
    "    obj_writer = csv.writer(obj_file,delimiter=\"\\t\")   #出力形式をTSVファイルに設定              \n",
    "    for property_num in range(18):\n",
    "        obj_writer.writerow([token_properties[property_num],true_properties_num[property_num],all_properties_num[property_num]])\n",
    "print(\"出力完了\")#プログラムが正常に終了した知らせ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e9b17e54",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "出力完了\n"
     ]
    }
   ],
   "source": [
    "#FILE_NAME = '実験実験'#場面の正解数を正しく数えられているかを評価するテスト用のファイル\n",
    "#SVO結果を評価するプログラム\n",
    "all_subject = 0 #すべての主語の数\n",
    "true_subject = 0 #正解の主語の数\n",
    "all_hasPredicate = 0 #すべての述語の数\n",
    "true_hasPredicate = 0 #正解の述語の数\n",
    "all_obj = 0 #すべての目的語の数\n",
    "true_obj = 0 #正解の目的語の数\n",
    "true_scene = 0 #全て正解だった場面数\n",
    "\n",
    "with open(\"../experiment/\"+FILE_NAME+\"SVO結果.tsv\",mode=\"r\",encoding='utf-8') as input_file:    #「SVO結果」を開く\n",
    "        read_list = list(csv.reader(input_file, delimiter='\\t'))#開いたファイルをtsv形式で読み込む\n",
    "        all_scene = int(read_list[-1][0]) #全場面数\n",
    "        for cols in read_list:  #読み込んだリストを一行ずつループ処理\n",
    "            if SUBJECT==cols[1]:      #主語を探索\n",
    "                all_subject += 1\n",
    "                if \"True\"==cols[3]:            #正解しているかどうか\n",
    "                    true_subject += 1\n",
    "            elif \"hasPredicate\"==cols[1] or \"hasProperty\" == cols[1]: #述語を探索\n",
    "                all_hasPredicate += 1\n",
    "                if \"True\"==cols[3]:            #正解しているかどうか\n",
    "                    true_hasPredicate += 1\n",
    "            elif OBJ==cols[1]:          #目的語を探索\n",
    "                all_obj += 1\n",
    "                if \"True\"==cols[3]:            #正解しているかどうか\n",
    "                    true_obj += 1\n",
    "            if cols[1]==\"対象文\":\n",
    "                if cols[5]==\"〇\" and cols[6]==\"〇\" and (cols[7]==\"〇\" or cols[7]==\"無\"):\n",
    "                    true_scene += 1\n",
    "\n",
    "with open(\"../experiment/\"+FILE_NAME+\"プロパティ.tsv\",mode=\"r\",encoding='utf-8') as obj_file:  \n",
    "    properties_list = list(csv.reader(obj_file, delimiter='\\t'))#開いたファイルをtsv形式で読み込む              \n",
    "    with open(\"../experiment/\"+FILE_NAME+\"SVO結果評価.tsv\",mode=\"w\",encoding='utf-8',newline='') as output_file:    #結果の評価をSVO結果評価に出力\n",
    "        writer = csv.writer(output_file,delimiter=\"\\t\")   #出力形式をTSVファイルに設定\n",
    "        writer.writerow([\"\",\"正解数\",\"総数\",\"割合\"])\n",
    "        writer.writerow([\"主語\",true_subject,all_subject,true_subject/all_subject])\n",
    "        writer.writerow([\"述語\",true_hasPredicate,all_hasPredicate,true_hasPredicate/all_subject])\n",
    "        writer.writerow([\"目的語\",true_obj,all_obj,true_obj/all_obj])\n",
    "        writer.writerow([\"全単語\",true_subject+true_hasPredicate+true_obj,all_subject+all_hasPredicate+all_obj,(true_subject+true_hasPredicate+true_obj)/(all_subject+all_hasPredicate+all_obj)])#主語、述語、目的語の合計\n",
    "        writer.writerow([\"全場面\",true_scene,all_scene,true_scene/all_scene])\n",
    "        for token_property in properties_list:\n",
    "            if int(token_property[2]):\n",
    "                writer.writerow([token_property[0],token_property[1],token_property[2],int(token_property[1])/int(token_property[2])]) \n",
    "            else:\n",
    "                writer.writerow([token_property[0],token_property[1],token_property[2],\"該当なし\"]) \n",
    "print(\"出力完了\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d2c0c2",
   "metadata": {},
   "source": [
    "転置対策〇\n",
    "\n",
    "正解の目的語プロパティ〇\n",
    "正解の述語プロパティ〇\n",
    "\n",
    "場面ごとのSVO〇部分と全問間違い分ける、目的語の有無（26だと目的語が存在しない場合もOと表示される）〇\n",
    "\n",
    "S〇V〇O〇→SVO\n",
    "S〇V〇O無→SVO\n",
    "S〇V〇O×→SV\n",
    "\n",
    "解決策\n",
    "S〇V〇O〇→○○〇\n",
    "S〇V〇O無→○○無\n",
    "S〇V〇O×→○○×\n",
    "\n",
    "一部正解なら△を入れる。〇\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b02297cf",
   "metadata": {},
   "source": [
    "インスタンス内関数の階層（インデントは関数内で使われる関数）\n",
    "\n",
    "・svo_parse（主語・述語・目的語の取得）\n",
    "\n",
    "　・subject_search\n",
    "\n",
    "　　・first_search(重複)\n",
    "\n",
    "　　・last_search（重複）\n",
    "\n",
    "　・obj_search\n",
    "　　\n",
    "　　・first_search(重複)\n",
    "\n",
    "　　・last_search（重複）\n",
    "　\n",
    " 　・hasPredicate_search\n",
    "  \n",
    "　　・first_search(重複)\n",
    "\n",
    "　　・last_search（重複）\n",
    "  \n",
    "・svo_print（取得した主語・述語・目的語をファイル形式で出力、目的語プロパティの種類ごとの正解数取得）\n",
    "\n",
    "　・svo_cheak（出力結果を比較する関数だが……目的語や述語のプロパティ分けが出来ないので目的語や述語の比較はsvo_printの中で行う）"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
